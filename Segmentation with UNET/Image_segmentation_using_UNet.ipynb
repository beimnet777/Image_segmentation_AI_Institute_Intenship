{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First let's import important libraries and packages"
      ],
      "metadata": {
        "id": "3WmdkN3STWnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z77vhq11Er-x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implimentation of the Unet Model"
      ],
      "metadata": {
        "id": "wCTCKs-k2ymQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_shape=(256, 256, 3)):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    \n",
        "    # Contracting path\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    \n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    \n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    \n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    drop4 = keras.layers.Dropout(0.5)(conv4)\n",
        "    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "    \n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "    drop5 = keras.layers.Dropout(0.5)(conv5)\n",
        "    \n",
        "   # Expanding path\n",
        "    up6 = keras.layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
        "    merge6 = keras.layers.concatenate([drop4, up6], axis=3)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = keras.layers.concatenate([conv3, up7], axis=3)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
        "    merge8 = keras.layers.concatenate([conv2, up8], axis=3)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
        "    merge9 = keras.layers.concatenate([conv1, up9], axis=3)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    outputs = keras.layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YG_38MV3bKBX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "VpAFDLeA28gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    #train the model\n",
        "    images_path = \"/content/drive/MyDrive/dataset/images/train\"\n",
        "    mask_path = \"/content/drive/MyDrive/dataset/annotations/train\"\n",
        "\n",
        "    image_files = [f for f in os.listdir(images_path)]\n",
        "    print(image_files)\n",
        "\n",
        "    X_train, Y_train = [], []\n",
        "\n",
        "    for image_file in image_files:\n",
        "\n",
        "      img = cv2.imread(os.path.join(images_path, image_file))\n",
        "      if img is not None:\n",
        "        img = cv2.resize(img, (256,256))\n",
        "        mask = cv2.imread(os.path.join(mask_path, image_file.split(\".\")[0]+\"_mask.png\"))\n",
        "        mask = cv2.resize(mask, (256, 256))\n",
        "        X_train.append(img)\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        mask = cv2.threshold(mask, 0, 1, cv2.THRESH_BINARY)[1]\n",
        "        mask=np.expand_dims(mask,axis=-1)\n",
        "        Y_train.append(mask)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    Y_train = np.array(Y_train)\n",
        "    print(\"hello\")\n",
        "    print(\"gonna fit now\")\n",
        "    print(X_train)\n",
        "    print(Y_train)\n",
        "    model = unet_model()\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics= [\"accuracy\"])\n",
        "    model.fit(X_train, Y_train, batch_size=16, epochs=50, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "To4sFVpEiZIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cgJn5fJUkhj",
        "outputId": "eb46405a-0266-4dc3-8266-cd38e2b5bee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1725.jpg', '1637.jpg', '258.jpg', '159.jpg', '561.jpg', '1544.jpg', '51.jpg', '519.jpg', '556.jpg', '450.jpg', '1464.jpg', '436.jpg', '640.jpg', '518.jpg', '1683.jpg', '164.jpg', '1230.jpg', '1682.jpg', '526.jpg', '614.jpg', '358.jpg', '687.jpg', '1590.jpg', '1001.jpg', '493.jpg', '1656.jpg', '362.jpg', '149.jpg', '1019.jpg', '1624.jpg', '699.jpg', '697.jpg', '175.jpg', '1048.jpg', '287.jpg', '1533.jpg', '656.jpg', '421.jpg', '1531.jpg', '318.jpg', '1387.jpg', '1561.jpg', '473.jpg', '1088.jpg', '24.jpg', '1579.jpg', '1124.jpg', '23.jpg', '160.jpg', '1424.jpg', '1098.jpg', '612.jpg', '250.jpg', '709.jpg', '1110.jpg', '1693.jpg', '426.jpg', '1696.jpg', '1030.jpg', '176.jpg', '341.jpg', '70.jpg', '1066.jpg', '1401.jpg', '342.jpg', '1662.jpg', '1534.jpg', '602.jpg', '325.jpg', '377.jpg', '1006.jpg', '186.jpg', '338.jpg', '397.jpg', '532.jpg', '238.jpg', '595.jpg', '1134.jpg', '284.jpg', '1542.jpg', '658.jpg', '1622.jpg', '688.jpg', '1468.jpg', '37.jpg', '1537.jpg', '433.jpg', '1699.jpg', '583.jpg', '1021.jpg', '1083.jpg', '379.jpg', '49.jpg', '1710.jpg', '157.jpg', '715.jpg', '222.jpg', '248.jpg', '356.jpg', '1478.jpg', '1581.jpg', '683.jpg', '372.jpg', '1027.jpg', '638.jpg', '444.jpg', '420.jpg', '575.jpg', '297.jpg', '55.jpg', '1439.jpg', '480.jpg', '375.jpg', '324.jpg', '1626.jpg', '60.jpg', '1070.jpg', '147.jpg', '311.jpg', '1589.jpg', '1183.jpg', '54.jpg', '1059.jpg', '581.jpg', '481.jpg', '510.jpg', '1700.jpg', '667.jpg', '387.jpg', '707.jpg', '587.jpg', '228.jpg', '1741.jpg', '365.jpg', '438.jpg', '1392.jpg', '56.jpg', '1639.jpg', '1742.jpg', '1054.jpg', '1511.jpg', '1495.jpg', '1080.jpg', '30.jpg', '178.jpg', '256.jpg', '1604.jpg', '608.jpg', '635.jpg', '609.jpg', '1043.jpg', '1455.jpg', '434.jpg', '1407.jpg', '1518.jpg', '185.jpg', '1614.jpg', '1041.jpg', '412.jpg', '1666.jpg', '1591.jpg', '1740.jpg', '1646.jpg', '1713.jpg', '408.jpg', '295.jpg', '1526.jpg', '589.jpg', '469.jpg', '343.jpg', '1035.jpg', '1649.jpg', '1698.jpg', '1664.jpg', '1194.jpg', '1737.jpg', '4.jpg', '541.jpg', '1007.jpg', '1075.jpg', '463.jpg', '440.jpg', '388.jpg', '1482.jpg', '1641.jpg', '41.jpg', '1654.jpg', '1546.jpg', '703.jpg', '1404.jpg', '691.jpg', '1574.jpg', '1091.jpg', '1521.jpg', '1557.jpg', '285.jpg', '405.jpg', '1063.jpg', '555.jpg', '278.jpg', '415.jpg', '1743.jpg', '1029.jpg', '1491.jpg', '462.jpg', '1487.jpg', '1554.jpg', '1548.jpg', '1018.jpg', '1451.jpg', '333.jpg', '1425.jpg', '3.jpg', '360.jpg', '246.jpg', '631.jpg', '596.jpg', '642.jpg', '1688.jpg', '554.jpg', '1394.jpg', '354.jpg', '1418.jpg', '1002.jpg', '1422.jpg', '1099.jpg', '1028.jpg', '1010.jpg', '686.jpg', '413.jpg', '503.jpg', '1193.jpg', '1151.jpg', '243.jpg', '288.jpg', '302.jpg', '1630.jpg', '598.jpg', '220.jpg', '407.jpg', '539.jpg', '1037.jpg', '1398.jpg', '58.jpg', '522.jpg', '314.jpg', '32.jpg', '232.jpg', '363.jpg', '345.jpg', '645.jpg', '597.jpg', '1152.jpg', '508.jpg', '1496.jpg', '409.jpg', '166.jpg', '705.jpg', '353.jpg', '253.jpg', '1218.jpg', '1602.jpg', '384.jpg', '662.jpg', '582.jpg', '227.jpg', '1695.jpg', '1651.jpg', '279.jpg', '1415.jpg', '1550.jpg', '600.jpg', '1112.jpg', '261.jpg', '225.jpg', '106.jpg', '1023.jpg', '340.jpg', '1529.jpg', '208.jpg', '283.jpg', '1051.jpg', '28.jpg', '1434.jpg', '646.jpg', '684.jpg', '389.jpg', '150.jpg', '1685.jpg', '1744.jpg', '1469.jpg', '1470.jpg', '269.jpg', '649.jpg', '1490.jpg', '344.jpg', '661.jpg', '1638.jpg', '1069.jpg', '1228.jpg', '1403.jpg', '1370.jpg', '61.jpg', '233.jpg', '666.jpg', '35.jpg', '1417.jpg', '1485.jpg', '1068.jpg', '1453.jpg', '562.jpg', '774.jpg', '867.jpg', '832.jpg', '73.jpg', '817.jpg', '982.jpg', '952.jpg', '874.jpg', '884.jpg', '746.jpg', '941.jpg', '769.jpg', '93.jpg', '855.jpg', '875.jpg', '754.jpg', '815.jpg', '96.jpg', '717.jpg', '839.jpg', '988.jpg', '870.jpg', '967.jpg', '751.jpg', '734.jpg', '764.jpg', '848.jpg', '986.jpg', '829.jpg', '735.jpg', '830.jpg', '721.jpg', '736.jpg', '79.jpg', '90.jpg', '842.jpg', '755.jpg', '864.jpg', '730.jpg', '779.jpg', '841.jpg', '808.jpg', '72.jpg', '745.jpg', '940.jpg', '727.jpg', '912.jpg', '851.jpg', '784.jpg', '980.jpg', '856.jpg', '732.jpg', '795.jpg', '910.jpg', '819.jpg', '757.jpg', '94.jpg', '898.jpg', '783.jpg', '835.jpg', '810.jpg', '911.jpg', '76.jpg', '850.jpg', '81.jpg', '926.jpg', '85.jpg', '837.jpg', '99.jpg', '74.jpg', '803.jpg', '990.jpg', '722.jpg', '95.jpg', '880.jpg', '953.jpg', '750.jpg', '726.jpg', '741.jpg', '887.jpg', '942.jpg', '914.jpg', '920.jpg', '744.jpg', '902.jpg', '987.jpg', '879.jpg', '981.jpg', '.ipynb_checkpoints']\n",
            "hello\n",
            "gonna fit now\n",
            "[[[[188 195 198]\n",
            "   [189 196 199]\n",
            "   [190 197 200]\n",
            "   ...\n",
            "   [146 154 154]\n",
            "   [141 153 153]\n",
            "   [142 154 154]]\n",
            "\n",
            "  [[188 195 198]\n",
            "   [189 196 199]\n",
            "   [189 196 199]\n",
            "   ...\n",
            "   [146 154 154]\n",
            "   [141 153 153]\n",
            "   [141 153 153]]\n",
            "\n",
            "  [[188 195 198]\n",
            "   [190 197 200]\n",
            "   [189 196 199]\n",
            "   ...\n",
            "   [145 153 153]\n",
            "   [141 153 153]\n",
            "   [141 153 153]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[190 197 200]\n",
            "   [191 198 201]\n",
            "   [192 199 202]\n",
            "   ...\n",
            "   [ 87  95  94]\n",
            "   [ 86  94  93]\n",
            "   [ 85  93  92]]\n",
            "\n",
            "  [[191 198 201]\n",
            "   [191 198 201]\n",
            "   [192 199 202]\n",
            "   ...\n",
            "   [ 86  94  93]\n",
            "   [ 85  93  92]\n",
            "   [ 84  92  91]]\n",
            "\n",
            "  [[191 198 201]\n",
            "   [193 200 203]\n",
            "   [192 199 202]\n",
            "   ...\n",
            "   [ 86  94  93]\n",
            "   [ 85  93  92]\n",
            "   [ 85  93  92]]]\n",
            "\n",
            "\n",
            " [[[196 203 206]\n",
            "   [196 203 206]\n",
            "   [196 203 206]\n",
            "   ...\n",
            "   [155 163 163]\n",
            "   [154 162 162]\n",
            "   [154 162 162]]\n",
            "\n",
            "  [[196 203 206]\n",
            "   [196 203 206]\n",
            "   [196 203 206]\n",
            "   ...\n",
            "   [153 161 161]\n",
            "   [154 162 162]\n",
            "   [154 162 162]]\n",
            "\n",
            "  [[195 202 205]\n",
            "   [196 203 206]\n",
            "   [196 203 206]\n",
            "   ...\n",
            "   [152 160 160]\n",
            "   [155 163 163]\n",
            "   [153 161 161]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[197 205 205]\n",
            "   [197 205 205]\n",
            "   [197 205 205]\n",
            "   ...\n",
            "   [108 116 115]\n",
            "   [107 115 114]\n",
            "   [105 113 112]]\n",
            "\n",
            "  [[198 206 206]\n",
            "   [197 205 205]\n",
            "   [198 206 206]\n",
            "   ...\n",
            "   [110 118 117]\n",
            "   [106 114 113]\n",
            "   [105 113 112]]\n",
            "\n",
            "  [[198 206 206]\n",
            "   [197 205 205]\n",
            "   [200 208 208]\n",
            "   ...\n",
            "   [108 116 115]\n",
            "   [106 114 113]\n",
            "   [105 113 112]]]\n",
            "\n",
            "\n",
            " [[[172 177 186]\n",
            "   [171 176 185]\n",
            "   [171 175 186]\n",
            "   ...\n",
            "   [163 172 185]\n",
            "   [162 171 184]\n",
            "   [162 171 184]]\n",
            "\n",
            "  [[170 175 184]\n",
            "   [171 176 185]\n",
            "   [171 175 186]\n",
            "   ...\n",
            "   [163 172 185]\n",
            "   [162 171 184]\n",
            "   [162 171 184]]\n",
            "\n",
            "  [[171 176 185]\n",
            "   [171 176 185]\n",
            "   [172 176 187]\n",
            "   ...\n",
            "   [164 173 186]\n",
            "   [161 170 183]\n",
            "   [162 171 184]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[168 173 182]\n",
            "   [169 174 183]\n",
            "   [171 176 185]\n",
            "   ...\n",
            "   [159 171 181]\n",
            "   [159 171 181]\n",
            "   [158 170 180]]\n",
            "\n",
            "  [[169 174 183]\n",
            "   [169 174 183]\n",
            "   [171 176 185]\n",
            "   ...\n",
            "   [159 171 181]\n",
            "   [158 170 180]\n",
            "   [159 171 181]]\n",
            "\n",
            "  [[169 174 183]\n",
            "   [169 174 183]\n",
            "   [169 174 183]\n",
            "   ...\n",
            "   [159 171 181]\n",
            "   [158 170 180]\n",
            "   [157 169 179]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[183 190 193]\n",
            "   [184 191 194]\n",
            "   [184 191 194]\n",
            "   ...\n",
            "   [162 169 172]\n",
            "   [163 170 173]\n",
            "   [163 170 173]]\n",
            "\n",
            "  [[183 190 193]\n",
            "   [184 191 194]\n",
            "   [184 191 194]\n",
            "   ...\n",
            "   [164 171 174]\n",
            "   [163 170 173]\n",
            "   [163 170 173]]\n",
            "\n",
            "  [[183 190 193]\n",
            "   [185 192 195]\n",
            "   [184 191 194]\n",
            "   ...\n",
            "   [163 170 173]\n",
            "   [163 170 173]\n",
            "   [163 170 173]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[174 186 188]\n",
            "   [174 186 188]\n",
            "   [173 185 187]\n",
            "   ...\n",
            "   [164 171 174]\n",
            "   [164 171 174]\n",
            "   [166 173 176]]\n",
            "\n",
            "  [[174 186 188]\n",
            "   [174 186 188]\n",
            "   [174 186 188]\n",
            "   ...\n",
            "   [165 172 175]\n",
            "   [163 170 173]\n",
            "   [166 173 176]]\n",
            "\n",
            "  [[174 186 188]\n",
            "   [174 186 188]\n",
            "   [174 186 188]\n",
            "   ...\n",
            "   [165 172 175]\n",
            "   [165 172 175]\n",
            "   [164 171 174]]]\n",
            "\n",
            "\n",
            " [[[219 220 224]\n",
            "   [218 219 223]\n",
            "   [217 218 222]\n",
            "   ...\n",
            "   [221 220 222]\n",
            "   [221 220 222]\n",
            "   [221 220 222]]\n",
            "\n",
            "  [[217 218 222]\n",
            "   [218 219 223]\n",
            "   [219 220 224]\n",
            "   ...\n",
            "   [221 220 222]\n",
            "   [221 220 222]\n",
            "   [221 220 222]]\n",
            "\n",
            "  [[218 219 223]\n",
            "   [218 219 223]\n",
            "   [219 220 224]\n",
            "   ...\n",
            "   [221 220 222]\n",
            "   [221 220 222]\n",
            "   [221 220 222]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[217 218 222]\n",
            "   [214 215 219]\n",
            "   [216 217 221]\n",
            "   ...\n",
            "   [185 189 194]\n",
            "   [184 188 193]\n",
            "   [182 186 191]]\n",
            "\n",
            "  [[215 216 220]\n",
            "   [215 216 220]\n",
            "   [216 217 221]\n",
            "   ...\n",
            "   [182 185 193]\n",
            "   [179 185 192]\n",
            "   [176 182 189]]\n",
            "\n",
            "  [[217 218 222]\n",
            "   [215 216 220]\n",
            "   [216 217 221]\n",
            "   ...\n",
            "   [179 181 191]\n",
            "   [174 181 190]\n",
            "   [171 178 187]]]\n",
            "\n",
            "\n",
            " [[[197 199 210]\n",
            "   [200 202 213]\n",
            "   [200 202 213]\n",
            "   ...\n",
            "   [172 184 194]\n",
            "   [170 182 192]\n",
            "   [169 181 191]]\n",
            "\n",
            "  [[200 202 213]\n",
            "   [197 199 210]\n",
            "   [200 202 213]\n",
            "   ...\n",
            "   [172 184 194]\n",
            "   [170 182 192]\n",
            "   [171 183 193]]\n",
            "\n",
            "  [[200 202 213]\n",
            "   [200 202 213]\n",
            "   [200 202 213]\n",
            "   ...\n",
            "   [170 182 192]\n",
            "   [170 182 192]\n",
            "   [172 184 194]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[201 205 216]\n",
            "   [200 204 215]\n",
            "   [201 205 216]\n",
            "   ...\n",
            "   [180 190 200]\n",
            "   [182 192 202]\n",
            "   [182 192 202]]\n",
            "\n",
            "  [[201 205 216]\n",
            "   [201 205 216]\n",
            "   [203 207 218]\n",
            "   ...\n",
            "   [182 192 202]\n",
            "   [179 189 199]\n",
            "   [181 191 201]]\n",
            "\n",
            "  [[201 205 216]\n",
            "   [201 205 216]\n",
            "   [203 207 218]\n",
            "   ...\n",
            "   [182 192 202]\n",
            "   [179 189 199]\n",
            "   [180 190 200]]]]\n",
            "[[[[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]]\n",
            "\n",
            "\n",
            " [[[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]]\n",
            "\n",
            "\n",
            " [[[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]]\n",
            "\n",
            "\n",
            " [[[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]]\n",
            "\n",
            "\n",
            " [[[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]\n",
            "\n",
            "  [[0]\n",
            "   [0]\n",
            "   [0]\n",
            "   ...\n",
            "   [0]\n",
            "   [0]\n",
            "   [0]]]]\n",
            "Epoch 1/50\n",
            "20/20 [==============================] - 36s 1s/step - loss: 0.3759 - accuracy: 0.8765 - val_loss: 0.0230 - val_accuracy: 0.9932\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 18s 890ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.0131 - val_accuracy: 0.9953\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 18s 912ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.0123 - val_accuracy: 0.9955\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 18s 909ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.0142 - val_accuracy: 0.9947\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 19s 933ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0107 - val_accuracy: 0.9961\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 19s 932ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 19s 951ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0086 - val_accuracy: 0.9968\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 19s 955ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 19s 971ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0079 - val_accuracy: 0.9972\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 19s 966ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 19s 964ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.0069 - val_accuracy: 0.9973\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 19s 976ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.0074 - val_accuracy: 0.9971\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 19s 971ms/step - loss: 0.0067 - accuracy: 0.9974 - val_loss: 0.0079 - val_accuracy: 0.9969\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 19s 978ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 0.0066 - val_accuracy: 0.9974\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 20s 984ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.0082 - val_accuracy: 0.9967\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 20s 996ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.0056 - val_accuracy: 0.9978\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 20s 997ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0062 - val_accuracy: 0.9976\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 20s 998ms/step - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0056 - val_accuracy: 0.9978\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 20s 996ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0055 - val_accuracy: 0.9979\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 20s 1000ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0073 - val_accuracy: 0.9971\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.0066 - val_accuracy: 0.9974\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.0061 - val_accuracy: 0.9976\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.0055 - val_accuracy: 0.9978\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0049 - accuracy: 0.9980 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.0055 - val_accuracy: 0.9979\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0064 - val_accuracy: 0.9975\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0056 - val_accuracy: 0.9979\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0055 - val_accuracy: 0.9978\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.0067 - val_accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0047 - accuracy: 0.9981 - val_loss: 0.0064 - val_accuracy: 0.9975\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0052 - val_accuracy: 0.9980\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0059 - val_accuracy: 0.9977\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.0059 - val_accuracy: 0.9977\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9979\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9980\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.0063 - val_accuracy: 0.9976\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9982\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 0.9980\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9982\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.0061 - val_accuracy: 0.9977\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 0.0072 - val_accuracy: 0.9973\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9979\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.0056 - val_accuracy: 0.9979\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0052 - val_accuracy: 0.9980\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0056 - val_accuracy: 0.9978\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Model"
      ],
      "metadata": {
        "id": "chyUkIdA3AQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = \"/content/drive/MyDrive/dataset/images/test\"\n",
        "mask_path = \"/content/drive/MyDrive/dataset/annotations/test\"\n",
        "\n",
        "# Get a list of all the image files in the test images directory\n",
        "image_files = os.listdir(images_path)\n",
        "\n",
        "# Create lists to store the test images and masks\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "# Loop through the test images and masks and preprocess them\n",
        "for image_file in image_files:\n",
        "    # Load the image\n",
        "    img = cv2.imread(os.path.join(images_path, image_file))\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (256,256))\n",
        "        \n",
        "        # Load and preprocess the mask\n",
        "        mask = cv2.imread(os.path.join(mask_path, image_file.split(\".\")[0]+\"_mask.png\"))\n",
        "        mask = cv2.resize(mask, (256, 256))\n",
        "        \n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        mask = cv2.threshold(mask, 0, 1, cv2.THRESH_BINARY)[1]\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        \n",
        "        # Add the image and mask to the test lists\n",
        "        X_test.append(img)\n",
        "        Y_test.append(mask)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "model = unet_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics= [\"accuracy\"])\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "print(test_loss)\n",
        "print(test_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Convert the predicted masks to the same data type as the Y_test masks\n",
        "# Y_pred = np.round(Y_pred).astype(np.uint8)\n",
        "\n",
        "\n",
        "# # Calculate the dice coefficient for each image in the test set\n",
        "# dice_scores = []\n",
        "# for i in range(len(Y_test)):\n",
        "#     dice = dice_coef(Y_test[i], Y_pred[i])\n",
        "#     dice_scores.append(dice)\n",
        "\n",
        "# # Calculate the average dice coefficient for the test set\n",
        "# average_dice = np.mean(dice_scores)\n",
        "\n",
        "# print(\"Average dice coefficient:\", average_dice)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig18vpaQdZM1",
        "outputId": "a5d4c28b-5d38-43d6-bfdf-d80dde3c9bbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 458ms/step\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 1.5186 - accuracy: 0.6515\n",
            "1.5185644626617432\n",
            "0.6514761447906494\n"
          ]
        }
      ]
    }
  ]
}