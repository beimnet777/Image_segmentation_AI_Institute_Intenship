{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First let's import important libraries and packages"
      ],
      "metadata": {
        "id": "3WmdkN3STWnw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z77vhq11Er-x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implimentation of the Unet Model"
      ],
      "metadata": {
        "id": "wCTCKs-k2ymQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_shape=(256, 256, 3)):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    \n",
        "    # Contracting path\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    \n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    \n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    \n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    drop4 = keras.layers.Dropout(0.5)(conv4)\n",
        "    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "    \n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = keras.layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "    drop5 = keras.layers.Dropout(0.5)(conv5)\n",
        "    \n",
        "   # Expanding path\n",
        "    up6 = keras.layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
        "    merge6 = keras.layers.concatenate([drop4, up6], axis=3)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = keras.layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = keras.layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = keras.layers.concatenate([conv3, up7], axis=3)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = keras.layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = keras.layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
        "    merge8 = keras.layers.concatenate([conv2, up8], axis=3)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = keras.layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
        "    merge9 = keras.layers.concatenate([conv1, up9], axis=3)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "    outputs = keras.layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YG_38MV3bKBX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "VpAFDLeA28gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    #train the model\n",
        "    images_path = \"/content/drive/MyDrive/dataset/images/train\"\n",
        "    mask_path = \"/content/drive/MyDrive/dataset/annotations/train\"\n",
        "\n",
        "    image_files = [f for f in os.listdir(images_path)]\n",
        "    \n",
        "\n",
        "    X_train, Y_train = [], []\n",
        "\n",
        "    for image_file in image_files:\n",
        "\n",
        "      img = cv2.imread(os.path.join(images_path, image_file))\n",
        "      if img is not None:\n",
        "        img = cv2.resize(img, (256,256))\n",
        "        mask = cv2.imread(os.path.join(mask_path, image_file.split(\".\")[0]+\"_mask.png\"))\n",
        "        mask = cv2.resize(mask, (256, 256))\n",
        "        X_train.append(img)\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        mask = cv2.threshold(mask, 0, 1, cv2.THRESH_BINARY)[1]\n",
        "        mask=np.expand_dims(mask,axis=-1)\n",
        "        Y_train.append(mask)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    Y_train = np.array(Y_train)\n",
        "    \n",
        "    model = unet_model()\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics= [\"accuracy\"])\n",
        "    model.fit(X_train, Y_train, batch_size=16, epochs=25, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "To4sFVpEiZIf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cgJn5fJUkhj",
        "outputId": "ce528bb4-6b61-4655-c697-62619895ee5b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "20/20 [==============================] - 54s 2s/step - loss: 5.4264 - accuracy: 0.6411 - val_loss: 0.0826 - val_accuracy: 0.9711\n",
            "Epoch 2/25\n",
            "20/20 [==============================] - 23s 1s/step - loss: 0.0686 - accuracy: 0.9803 - val_loss: 0.0340 - val_accuracy: 0.9894\n",
            "Epoch 3/25\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.0218 - val_accuracy: 0.9924\n",
            "Epoch 4/25\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 0.0180 - val_accuracy: 0.9935\n",
            "Epoch 5/25\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.0193 - val_accuracy: 0.9932\n",
            "Epoch 6/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0143 - val_accuracy: 0.9949\n",
            "Epoch 7/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0132 - val_accuracy: 0.9953\n",
            "Epoch 8/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0124 - val_accuracy: 0.9957\n",
            "Epoch 9/25\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0097 - val_accuracy: 0.9967\n",
            "Epoch 10/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0087 - val_accuracy: 0.9969\n",
            "Epoch 11/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0095 - val_accuracy: 0.9967\n",
            "Epoch 12/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0086 - val_accuracy: 0.9968\n",
            "Epoch 13/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.0086 - val_accuracy: 0.9968\n",
            "Epoch 14/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0079 - val_accuracy: 0.9970\n",
            "Epoch 15/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0058 - val_accuracy: 0.9978\n",
            "Epoch 16/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0060 - val_accuracy: 0.9977\n",
            "Epoch 17/25\n",
            "20/20 [==============================] - 22s 1s/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0057 - val_accuracy: 0.9978\n",
            "Epoch 18/25\n",
            "20/20 [==============================] - 22s 1s/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0087 - val_accuracy: 0.9966\n",
            "Epoch 19/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.0073 - val_accuracy: 0.9971\n",
            "Epoch 20/25\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0079 - val_accuracy: 0.9970\n",
            "Epoch 21/25\n",
            "20/20 [==============================] - 22s 1s/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.0068 - val_accuracy: 0.9973\n",
            "Epoch 22/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0058 - val_accuracy: 0.9977\n",
            "Epoch 23/25\n",
            "20/20 [==============================] - 21s 1s/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0054 - val_accuracy: 0.9979\n",
            "Epoch 24/25\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0057 - val_accuracy: 0.9977\n",
            "Epoch 25/25\n",
            "20/20 [==============================] - 20s 1s/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.0053 - val_accuracy: 0.9979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Model"
      ],
      "metadata": {
        "id": "chyUkIdA3AQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = \"/content/drive/MyDrive/dataset/images/test\"\n",
        "mask_path = \"/content/drive/MyDrive/dataset/annotations/test\"\n",
        "\n",
        "# Get a list of all the image files in the test images directory\n",
        "image_files = os.listdir(images_path)\n",
        "\n",
        "# Create lists to store the test images and masks\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "# Loop through the test images and masks and preprocess them\n",
        "for image_file in image_files:\n",
        "    # Load the image\n",
        "    img = cv2.imread(os.path.join(images_path, image_file))\n",
        "    if img is not None:\n",
        "        img = cv2.resize(img, (256,256))\n",
        "        \n",
        "        # Load and preprocess the mask\n",
        "        mask = cv2.imread(os.path.join(mask_path, image_file.split(\".\")[0]+\"_mask.png\"))\n",
        "        mask = cv2.resize(mask, (256, 256))\n",
        "        \n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        mask = cv2.threshold(mask, 0, 1, cv2.THRESH_BINARY)[1]\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        \n",
        "        # Add the image and mask to the test lists\n",
        "        X_test.append(img)\n",
        "        Y_test.append(mask)\n",
        "X_test = np.array(X_test)\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "model = unet_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"binary_crossentropy\", metrics= [\"accuracy\"])\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "\n",
        "print(test_loss)\n",
        "print(test_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Convert the predicted masks to the same data type as the Y_test masks\n",
        "# Y_pred = np.round(Y_pred).astype(np.uint8)\n",
        "\n",
        "\n",
        "# # Calculate the dice coefficient for each image in the test set\n",
        "# dice_scores = []\n",
        "# for i in range(len(Y_test)):\n",
        "#     dice = dice_coef(Y_test[i], Y_pred[i])\n",
        "#     dice_scores.append(dice)\n",
        "\n",
        "# # Calculate the average dice coefficient for the test set\n",
        "# average_dice = np.mean(dice_scores)\n",
        "\n",
        "# print(\"Average dice coefficient:\", average_dice)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig18vpaQdZM1",
        "outputId": "a5d4c28b-5d38-43d6-bfdf-d80dde3c9bbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 458ms/step\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 1.5186 - accuracy: 0.6515\n",
            "1.5185644626617432\n",
            "0.6514761447906494\n"
          ]
        }
      ]
    }
  ]
}